<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Numerical Methods Quiz</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            background-color: #f4f4f4;
        }
        h2 {
            text-align: center;
            color: #333;
        }
        .question {
            margin-bottom: 20px;
            border: 1px solid #ccc;
            padding: 15px;
            background-color: #fff;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .options {
            margin-left: 20px;
            line-height: 1.6;
        }
        input[type="radio"] {
            margin-right: 10px;
        }
        label {
            cursor: pointer;
        }
        .feedback {
            margin-top: 5px;
            font-weight: bold;
            display: none;
        }
        .correct {
            color: #28a745;
        }
        .incorrect {
            color: #dc3545;
        }
        .explanation {
            color: #555;
            font-style: italic;
            margin-top: 5px;
            display: none;
        }
        #score {
            margin-top: 20px;
            font-weight: bold;
            text-align: center;
            font-size: 1.2em;
            color: #333;
        }
    </style>
</head>
<body>
    <h2>Numerical Methods Quiz</h2>
    <div id="quizContainer"></div>
    <script>
        // Array of 50 questions
        const questions = [
            // First 8 Questions from Images (Placeholders as per your previous prompt)
            {
                text: "What is the primary purpose of numerical methods in engineering?",
                options: [
                    "To provide exact solutions to mathematical problems",
                    "To approximate solutions when exact methods are impractical",
                    "To eliminate all errors in computations",
                    "To simplify complex equations into linear forms"
                ],
                correctIndex: 1,
                explanation: "Numerical methods are essential in engineering because they offer practical approximate solutions to problems where exact analytical solutions are either too complex or impossible to derive, such as in real-world simulations or nonlinear systems."
            },
            {
                text: "Which of the following is NOT a reason for using numerical methods?",
                options: [
                    "No analytical solution exists",
                    "Analytical solution is too complicated",
                    "To avoid using computers",
                    "To handle large systems of equations"
                ],
                correctIndex: 2,
                explanation: "Numerical methods typically rely on computational tools like computers to solve problems efficiently, especially for large or complex systems, making 'avoiding computers' an incorrect reason."
            },
            {
                text: "What is the main difference between truncation error and round-off error?",
                options: [
                    "Truncation error is due to approximating mathematical processes, while round-off error is due to finite precision arithmetic",
                    "Truncation error occurs in iterative methods, while round-off error occurs in direct methods",
                    "Truncation error is always larger than round-off error",
                    "Round-off error can be eliminated by using more terms in the approximation"
                ],
                correctIndex: 0,
                explanation: "Truncation error arises when we approximate an infinite process (e.g., cutting off a series), while round-off error occurs because computers use finite precision to represent numbers, leading to small inaccuracies."
            },
            {
                text: "How many significant figures are in the number 0.002540?",
                options: [
                    "7",
                    "5",
                    "4",
                    "6"
                ],
                correctIndex: 2,
                explanation: "In 0.002540, leading zeros are not significant. The significant figures are 2, 5, 4, and 0 (after the decimal), totaling four."
            },
            {
                text: "What is the purpose of the Taylor series in numerical methods?",
                options: [
                    "To approximate functions using polynomials",
                    "To solve differential equations exactly",
                    "To eliminate round-off errors",
                    "To convert nonlinear equations to linear ones"
                ],
                correctIndex: 0,
                explanation: "The Taylor series approximates functions as polynomials, which are easier to manipulate numerically, enabling methods like differentiation or integration approximations."
            },
            {
                text: "In the context of root-finding, what does it mean for a method to be 'quadratically convergent'?",
                options: [
                    "The error decreases linearly with each iteration",
                    "The error decreases quadratically with each iteration",
                    "The method requires two initial guesses",
                    "The method always finds the root in two steps"
                ],
                correctIndex: 1,
                explanation: "Quadratic convergence means the error in each iteration is proportional to the square of the previous error, leading to very rapid convergence near the root."
            },
            {
                text: "Which of the following methods requires the function to change sign over the interval?",
                options: [
                    "Newton-Raphson method",
                    "Secant method",
                    "Bisection method",
                    "Fixed-point iteration"
                ],
                correctIndex: 2,
                explanation: "The bisection method relies on the intermediate value theorem, requiring the function to change sign across the interval to guarantee a root exists within it."
            },
            {
                text: "What is a potential pitfall of the Newton-Raphson method?",
                options: [
                    "It always converges slowly",
                    "It requires the derivative of the function",
                    "It can diverge if the initial guess is poor",
                    "It only works for polynomial functions"
                ],
                correctIndex: 2,
                explanation: "While it requires the derivative (option b is true), the more critical pitfall is that a poor initial guess or a zero derivative can cause the Newton-Raphson method to diverge or fail."
            },
            // Remaining 42 Questions from Document Topics
            {
                text: "What is one key advantage of numerical methods over analytical methods?",
                options: [
                    "They always provide exact solutions",
                    "They can handle problems where analytical solutions are impractical",
                    "They eliminate the need for computers",
                    "They are only used for linear equations"
                ],
                correctIndex: 1,
                explanation: "Numerical methods excel in solving complex problems (e.g., nonlinear equations or large systems) where analytical solutions are either unavailable or too cumbersome to compute."
            },
            {
                text: "Which of the following is NOT typically a topic covered in a numerical methods course?",
                options: [
                    "Solution of linear equations",
                    "Numerical integration",
                    "Abstract algebra",
                    "Solution of differential equations"
                ],
                correctIndex: 2,
                explanation: "Numerical methods courses focus on computational techniques like solving equations or integration, whereas abstract algebra deals with theoretical structures (e.g., groups, rings) unrelated to these practical topics."
            },
            {
                text: "Why are numerical methods important in engineering?",
                options: [
                    "They allow for the solution of complex real-world problems",
                    "They provide exact solutions to all equations",
                    "They eliminate the need for mathematical modeling",
                    "They are only used in theoretical research"
                ],
                correctIndex: 0,
                explanation: "Engineers use numerical methods to tackle real-world challenges, such as fluid dynamics or structural analysis, where exact solutions are often infeasible."
            },
            {
                text: "What is the difference between accuracy and precision?",
                options: [
                    "Accuracy is closeness to the true value, precision is consistency",
                    "Precision is closeness to the true value, accuracy is consistency",
                    "They are the same thing",
                    "Accuracy is only important in measurements, precision in calculations"
                ],
                correctIndex: 0,
                explanation: "Accuracy measures how close a result is to the true value, while precision measures how repeatable or consistent results are, regardless of their correctness."
            },
            {
                text: "How many significant figures are in the number 100.0?",
                options: [
                    "1",
                    "2",
                    "3",
                    "4"
                ],
                correctIndex: 3,
                explanation: "In 100.0, all digits (1, 0, 0, and the trailing 0 after the decimal) are significant, totaling four significant figures."
            },
            {
                text: "What is a round-off error?",
                options: [
                    "An error introduced by approximating a mathematical procedure",
                    "An error due to the finite precision of computer arithmetic",
                    "An error caused by incorrect algorithm implementation",
                    "An error that occurs only in iterative methods"
                ],
                correctIndex: 1,
                explanation: "Round-off errors occur because computers use finite bits to represent numbers, leading to small discrepancies (e.g., representing π as 3.14159 instead of its infinite value)."
            },
            {
                text: "What is the purpose of normalizing a floating-point number?",
                options: [
                    "To increase the number of significant figures",
                    "To ensure the mantissa is within a specific range",
                    "To eliminate round-off errors",
                    "To convert the number to an integer"
                ],
                correctIndex: 1,
                explanation: "Normalization adjusts the mantissa (e.g., to [0.1, 1) in base-10 or [1, 2) in base-2) to standardize representation and maximize precision in floating-point arithmetic."
            },
            {
                text: "In binary floating-point representation, what is the normalized form?",
                options: [
                    "±d.ddd... × 10^n",
                    "±1.ddd... × 2^n",
                    "±0.ddd... × 2^n",
                    "±1.ddd... × 10^n"
                ],
                correctIndex: 1,
                explanation: "In binary systems (e.g., IEEE 754), normalized floating-point numbers are written as ±1.ddd... × 2^n, where the leading 1 is implied, optimizing precision."
            },
            {
                text: "What is the main advantage of using double precision over single precision?",
                options: [
                    "Faster computation",
                    "Reduced storage requirements",
                    "Increased precision and range",
                    "Simpler implementation"
                ],
                correctIndex: 2,
                explanation: "Double precision uses 64 bits (vs. 32 for single), providing more bits for the mantissa and exponent, thus increasing both precision and the range of representable numbers."
            },
            {
                text: "Why do some machines use chopping instead of rounding?",
                options: [
                    "Chopping is more accurate",
                    "Chopping is faster and simpler",
                    "Chopping eliminates all errors",
                    "Chopping is required for integer operations"
                ],
                correctIndex: 1,
                explanation: "Chopping simply truncates excess digits, which is computationally faster and simpler than rounding, though it may introduce larger errors."
            },
            {
                text: "What is the approximate absolute percent relative error used for in numerical methods?",
                options: [
                    "To determine the exact true value",
                    "To assess convergence when the true value is unknown",
                    "To eliminate truncation errors",
                    "To calculate the derivative of the function"
                ],
                correctIndex: 1,
                explanation: "When the true value is unknown, this error metric compares successive approximations to decide if an iterative process has converged sufficiently."
            },
            {
                text: "What does the remainder term in the Taylor series represent?",
                options: [
                    "The exact value of the function",
                    "The error due to truncation",
                    "The derivative of the function",
                    "The initial guess for the root"
                ],
                correctIndex: 1,
                explanation: "The remainder term quantifies the error introduced by truncating the infinite Taylor series at a finite number of terms."
            },
            {
                text: "For a first-order Taylor series approximation, what is the order of the truncation error?",
                options: [
                    "O(h)",
                    "O(h^2)",
                    "O(h^3)",
                    "O(h^4)"
                ],
                correctIndex: 0,
                explanation: "A first-order Taylor approximation includes terms up to the first derivative, leaving a truncation error proportional to the step size h, denoted O(h)."
            },
            {
                text: "How does reducing the step size h affect the truncation error in a Taylor series approximation?",
                options: [
                    "It increases the error",
                    "It decreases the error",
                    "It has no effect",
                    "It eliminates the error"
                ],
                correctIndex: 1,
                explanation: "Smaller step sizes reduce the truncation error (e.g., O(h) becomes smaller as h decreases), improving the approximation’s accuracy."
            },
            {
                text: "What is the purpose of using more terms in a Taylor series expansion?",
                options: [
                    "To increase the computational speed",
                    "To reduce the truncation error",
                    "To eliminate round-off errors",
                    "To simplify the function"
                ],
                correctIndex: 1,
                explanation: "Adding more terms includes higher derivatives, reducing the truncation error by making the polynomial closer to the true function."
            },
            {
                text: "In the context of numerical differentiation, what does the central difference approximation improve?",
                options: [
                    "Computational speed",
                    "Accuracy of the derivative approximation",
                    "Elimination of round-off errors",
                    "Simplification of the function"
                ],
                correctIndex: 1,
                explanation: "Central difference (f(x+h) - f(x-h))/(2h) cancels more error terms than forward or backward differences, yielding a more accurate derivative approximation."
            },
            {
                text: "What is the significance of the Big O notation in error analysis?",
                options: [
                    "It indicates the exact error",
                    "It describes the order of the error term",
                    "It eliminates the error",
                    "It converts the error to a percentage"
                ],
                correctIndex: 1,
                explanation: "Big O notation (e.g., O(h^2)) describes how the error scales with a parameter like step size h, not its exact value."
            },
            {
                text: "If a method has a truncation error of O(h^3), what happens to the error when h is halved?",
                options: [
                    "It is reduced by a factor of 2",
                    "It is reduced by a factor of 4",
                    "It is reduced by a factor of 8",
                    "It remains the same"
                ],
                correctIndex: 2,
                explanation: "For O(h^3), halving h (h/2) reduces the error to (h/2)^3 = h^3/8, a factor of 8 reduction."
            },
            {
                text: "Why is the Taylor series useful in numerical methods?",
                options: [
                    "It provides exact solutions to all functions",
                    "It allows for the approximation of functions and their derivatives",
                    "It eliminates the need for initial guesses",
                    "It only works for polynomial functions"
                ],
                correctIndex: 1,
                explanation: "The Taylor series underpins many numerical techniques by approximating functions and their derivatives, facilitating error analysis and method development."
            },
            {
                text: "What is the main advantage of bracketing methods like bisection?",
                options: [
                    "They converge quickly",
                    "They always find a root if one exists in the interval",
                    "They do not require derivatives",
                    "They work for any continuous function"
                ],
                correctIndex: 1,
                explanation: "Bracketing methods guarantee convergence to a root if the initial interval contains one, due to the function changing sign (via the intermediate value theorem)."
            },
            {
                text: "In the bisection method, how is the interval updated?",
                options: [
                    "By choosing the subinterval where the function changes sign",
                    "By selecting the subinterval with the smaller function value",
                    "By averaging the two endpoints",
                    "By using the derivative at the midpoint"
                ],
                correctIndex: 0,
                explanation: "The interval is halved, and the subinterval where f(a)·f(m) < 0 (indicating a sign change) is kept, ensuring the root remains bracketed."
            },
            {
                text: "What is a disadvantage of the bisection method?",
                options: [
                    "It requires the derivative of the function",
                    "It can be slow to converge",
                    "It may not find multiple roots",
                    "It only works for linear functions"
                ],
                correctIndex: 1,
                explanation: "Bisection converges linearly (halving the interval each step), which is slower than quadratically convergent methods like Newton-Raphson."
            },
            {
                text: "How does the false-position method differ from the bisection method?",
                options: [
                    "It uses linear interpolation instead of midpoint selection",
                    "It requires the derivative of the function",
                    "It converges faster for all functions",
                    "It does not require initial guesses"
                ],
                correctIndex: 0,
                explanation: "False-position estimates the root using the line connecting the endpoints, often converging faster than bisection’s midpoint approach."
            },
            {
                text: "What is a potential issue with the false-position method?",
                options: [
                    "It always converges slowly",
                    "It may converge to a root outside the initial interval",
                    "It can get stuck if the function is flat",
                    "It requires multiple initial guesses"
                ],
                correctIndex: 2,
                explanation: "If the function is nearly flat at one end, that endpoint may remain fixed, slowing convergence significantly."
            },
            {
                text: "What is the Newton-Raphson method based on?",
                options: [
                    "Linear interpolation",
                    "Taylor series expansion",
                    "Bracketing the root",
                    "Random sampling"
                ],
                correctIndex: 1,
                explanation: "Newton-Raphson uses a first-order Taylor series to approximate the function, deriving the iterative formula x_{n+1} = x_n - f(x_n)/f'(x_n)."
            },
            {
                text: "What is required for the Newton-Raphson method to work?",
                options: [
                    "Two initial guesses that bracket the root",
                    "The function and its derivative",
                    "The function to be continuous",
                    "The function to be polynomial"
                ],
                correctIndex: 1,
                explanation: "The method needs both f(x) and f'(x) to compute each iteration, unlike bracketing methods that don’t use derivatives."
            },
            {
                text: "Why might the Newton-Raphson method fail?",
                options: [
                    "If the initial guess is too far from the root",
                    "If the derivative is zero at the root",
                    "If the function is not differentiable",
                    "All of the above"
                ],
                correctIndex: 3,
                explanation: "All these scenarios—poor initial guess, zero derivative, or non-differentiability—can cause divergence or undefined steps in Newton-Raphson."
            },
            {
                text: "How does the secant method approximate the derivative?",
                options: [
                    "Using a forward difference",
                    "Using a backward difference",
                    "Using a finite difference between two points",
                    "Using the exact derivative"
                ],
                correctIndex: 2,
                explanation: "The secant method approximates f'(x) as (f(x_n) - f(x_{n-1})) / (x_n - x_{n-1}), a finite difference using two prior points."
            },
            {
                text: "What is an advantage of the secant method over Newton-Raphson?",
                options: [
                    "It converges faster",
                    "It does not require the derivative",
                    "It always converges",
                    "It works for discontinuous functions"
                ],
                correctIndex: 1,
                explanation: "By avoiding explicit derivative computation, the secant method is simpler to implement when f'(x) is hard to derive."
            },
            {
                text: "What is a multiple root?",
                options: [
                    "A root where the function crosses the axis multiple times",
                    "A root where the function and its derivative are zero",
                    "A root that can be found using multiple methods",
                    "A root that is not unique"
                ],
                correctIndex: 1,
                explanation: "A multiple root (e.g., multiplicity 2) occurs where f(x) = 0 and f'(x) = 0, meaning the function is tangent to the x-axis."
            },
            {
                text: "Why do bracketing methods struggle with multiple roots?",
                options: [
                    "They require the function to change sign, which may not happen at even multiplicity roots",
                    "They converge too slowly",
                    "They require derivatives",
                    "They cannot handle nonlinear functions"
                ],
                correctIndex: 0,
                explanation: "Even multiplicity roots (e.g., x^2 = 0 at x = 0) don’t change sign, so bracketing methods like bisection may miss them."
            },
            {
                text: "What modification can be made to the Newton-Raphson method for multiple roots?",
                options: [
                    "Use a smaller step size",
                    "Use the modified Newton-Raphson formula involving second derivatives",
                    "Switch to a bracketing method",
                    "Increase the number of iterations"
                ],
                correctIndex: 1,
                explanation: "The modified formula, x_{n+1} = x_n - m·f(x_n)/f'(x_n) (where m is the multiplicity), or using f''(x), handles multiple roots effectively."
            },
            {
                text: "In the context of root-finding, what is the stopping criterion typically based on?",
                options: [
                    "The number of iterations",
                    "The approximate error being less than a tolerance",
                    "The function value being exactly zero",
                    "The derivative being zero"
                ],
                correctIndex: 1,
                explanation: "Iterations stop when the difference between successive approximations (e.g., |x_{n+1} - x_n|) falls below a tolerance, indicating sufficient accuracy."
            },
            {
                text: "What is the main difference between open and bracketing methods?",
                options: [
                    "Open methods require derivatives, bracketing do not",
                    "Bracketing methods guarantee convergence, open methods do not",
                    "Open methods are always faster",
                    "Bracketing methods are only for linear functions"
                ],
                correctIndex: 1,
                explanation: "Bracketing methods (e.g., bisection) ensure convergence if a root is bracketed, while open methods (e.g., Newton-Raphson) may diverge with a bad initial guess."
            },
            {
                text: "What is the primary reason for using numerical methods in chemical engineering?",
                options: [
                    "To avoid complex calculus",
                    "To model and solve real-world problems where analytical solutions are impractical",
                    "To eliminate the need for experimental data",
                    "To simplify all equations to linear forms"
                ],
                correctIndex: 1,
                explanation: "Numerical methods are essential in chemical engineering for modeling complex processes such as fluid dynamics, heat transfer, and chemical reactions where analytical solutions are often infeasible."
            },
            {
                text: "Which of the following best describes the role of algorithms in numerical methods?",
                options: [
                    "They provide exact solutions to mathematical problems",
                    "They are step-by-step procedures to approximate solutions",
                    "They eliminate all types of errors",
                    "They are only used for theoretical analysis"
                ],
                correctIndex: 1,
                explanation: "Algorithms in numerical methods are systematic procedures designed to compute approximate solutions to mathematical problems when exact solutions are impractical."
            },
            {
                text: "What is the effect of using a larger number of significant figures in computations?",
                options: [
                    "It increases round-off errors",
                    "It decreases round-off errors",
                    "It has no effect on errors",
                    "It eliminates truncation errors"
                ],
                correctIndex: 1,
                explanation: "Using more significant figures increases precision, reducing round-off errors caused by finite representation of numbers in computers."
            },
            {
                text: "In floating-point arithmetic, what is the purpose of the exponent?",
                options: [
                    "To determine the precision of the number",
                    "To indicate the position of the decimal point",
                    "To store the sign of the number",
                    "To eliminate round-off errors"
                ],
                correctIndex: 1,
                explanation: "The exponent in floating-point representation (e.g., ±d.ddd × 10^n) specifies the position of the decimal point, allowing representation of very large or small numbers."
            },
            {
                text: "What is the truncation error in the context of numerical integration?",
                options: [
                    "The error due to rounding numbers",
                    "The error from approximating the integral with a finite sum",
                    "The error caused by incorrect algorithm implementation",
                    "The error from using too many terms in the approximation"
                ],
                correctIndex: 1,
                explanation: "Truncation error in numerical integration arises when a continuous integral is approximated by a finite sum, omitting higher-order terms."
            },
            {
                text: "How does the order of a numerical method relate to its truncation error?",
                options: [
                    "Higher-order methods have larger truncation errors",
                    "Higher-order methods have smaller truncation errors for the same step size",
                    "The order does not affect the truncation error",
                    "Lower-order methods are always more accurate"
                ],
                correctIndex: 1,
                explanation: "Higher-order methods reduce truncation error more rapidly as step size decreases (e.g., O(h^4) vs. O(h^2)), improving accuracy."
            },
            {
                text: "What is the main advantage of the modified secant method over the standard secant method?",
                options: [
                    "It requires only one initial guess",
                    "It converges faster for all functions",
                    "It eliminates the need for derivatives",
                    "It always finds multiple roots"
                ],
                correctIndex: 0,
                explanation: "The modified secant method uses one initial guess and a perturbation to estimate the derivative, simplifying setup compared to the standard secant method’s two guesses."
            },
            {
                text: "Why might the Newton-Raphson method be preferred over bracketing methods for some functions?",
                options: [
                    "It guarantees convergence",
                    "It converges faster near the root",
                    "It does not require initial guesses",
                    "It works for discontinuous functions"
                ],
                correctIndex: 1,
                explanation: "Newton-Raphson often converges quadratically near a root, making it faster than linearly convergent bracketing methods like bisection, though it requires a good initial guess."
            }
        ];

        let score = 0;

        // Function to shuffle an array (Fisher-Yates algorithm)
        function shuffleArray(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
            return array;
        }

        // Function to shuffle options and track the correct answer
        function shuffleOptions(question) {
            const options = [...question.options];
            const correctAnswer = options[question.correctIndex];
            shuffleArray(options);
            const newCorrectIndex = options.indexOf(correctAnswer);
            return { shuffledOptions: options, newCorrectIndex };
        }

        // Generate quiz HTML
        let quizHTML = '';
        questions.forEach((q, index) => {
            const questionNumber = index + 1;
            const { shuffledOptions, newCorrectIndex } = shuffleOptions(q);
            const correctLetter = String.fromCharCode(65 + newCorrectIndex);
            quizHTML += `
                <div class="question" id="q${questionNumber}" data-correct-letter="${correctLetter}">
                    <p>${questionNumber}. ${q.text}</p>
                    <div class="options">
                        ${shuffledOptions.map((opt, i) => `
                            <div>
                                <label>
                                    <input type="radio" name="q${questionNumber}" value="${String.fromCharCode(65 + i)}" onchange="checkAnswer(${questionNumber}, this.value)">
                                    ${String.fromCharCode(65 + i)}. ${opt}
                                </label>
                            </div>
                        `).join('')}
                    </div>
                    <p class="feedback" id="feedback${questionNumber}"></p>
                    <p class="explanation" id="exp${questionNumber}">${q.explanation}</p>
                </div>
            `;
        });
        quizHTML += `<p id="score">Score: ${score}/${questions.length}</p>`;
        document.getElementById('quizContainer').innerHTML = quizHTML;

        // Function to check the user's answer
        function checkAnswer(questionNumber, selectedLetter) {
            const questionDiv = document.getElementById(`q${questionNumber}`);
            const correctLetter = questionDiv.getAttribute('data-correct-letter');
            const feedback = document.getElementById(`feedback${questionNumber}`);
            const explanation = document.getElementById(`exp${questionNumber}`);

            // Adjust score if the question was previously answered
            if (feedback.classList.contains('counted')) {
                if (feedback.innerHTML.includes('Correct')) {
                    score--;
                }
                feedback.classList.remove('counted');
            }

            // Check the answer and provide feedback
            if (selectedLetter === correctLetter) {
                feedback.innerHTML = '<span class="correct">Correct!</span>';
                feedback.style.display = 'block';
                explanation.style.display = 'none';
                score++;
                feedback.classList.add('counted');
            } else {
                feedback.innerHTML = `<span class="incorrect">Incorrect. The correct answer is ${correctLetter}.</span>`;
                feedback.style.display = 'block';
                explanation.style.display = 'block';
                feedback.classList.add('counted');
            }

            // Update the displayed score
            document.getElementById('score').textContent = `Score: ${score}/${questions.length}`;
        }
    </script>
</body>
</html>
